---
sidebar_label: "üîë Tokenizaci√≥n"
sidebar_position: 3
---

# üîë Tokenizaci√≥n

## üåü Introducci√≥n

Al momento de contar con un texto, los primeros pasos en el procesamiento de lenguaje natural se encuentra la tokenizaci√≥n. Lo que nos permite la tokenizaci√≥n, es la divisi√≥n en unidades m√°s peque√±as, ya se de palabras, oraciones o frases en forma de lista.

```python title="Ejemplo de tokenizaci√≥n en python"
texto = "¬°Hola! Me encuentro aprendiendo el proceso de tokenizaci√≥n en la mejor p√°gina de programaci√≥n en python."
tokens = texto.split() #Divide la cadena de texto en una lista de palabras
print(tokens)
```

## üßπ Tokenizaci√≥n de palabras

La tokenizaci√≥n de palabras desarma una secuencia de texto, ya sea de una oraci√≥n o de un p√°rrafo, en palabras individuales con base a al delimitador "espacio" (" ").

```python title="Ejemplo de tokenizaci√≥n de palabras con nltk"
import nltk

# Texto a tokenizar
texto = "¬°Hola! Me encuentro aprendiendo el proceso de tokenizaci√≥n en la mejor p√°gina de programaci√≥n en python."
tokens = nltk.word_tokenize(texto)

print(tokens)
```

Al final del proceso, los espacios que se hayan encontrado en la oraci√≥n, se dividen y se devuelven en una lista de palabras. Sin embargo, es importante destacar que esta tokenizaci√≥n puede llegar tener ciertos desaf√≠os, como la correcta separaci√≥n de palabras dependiendo el lenguaje (espa√±ol, ingles,etc.) que se use.

## üñäÔ∏è Tokenizaci√≥n de oraciones

Para la tokenizaci√≥n de oraciones, se emplea de la misma forma, pero su estructura cambia. Ahora, la tokenizaci√≥n se emplear√° mediante puntos ".", ya no por los espaciados.

```python title="Ejemplo de tokenizaci√≥n de oraciones con nltk"
import nltk

# Texto a tokenizar
texto = "¬°Hola! Me encuentro aprendiendo el proceso de tokenizaci√≥n en la mejor p√°gina de programaci√≥n en python."
tokens = nltk.sent_tokenize(texto)

print(tokens)
```
