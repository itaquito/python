---
sidebar_label: "游닇 Text Summarization"
sidebar_position: 11
---

# 游닇 Text Summarization

El resumen autom치tico de texto es una t칠cnica de procesamiento del lenguaje natural (NLP) que condensa uno o m치s documentos largos en un resumen m치s breve y significativo. En este proyecto, implementaremos un resumen extractivo, utilizando Python con las bibliotecas BeautifulSoup para hacer scraping web y NLTK para realizar la tokenizaci칩n y el an치lisis de frecuencia de palabras.

## 游닄 Instalaci칩n de librer칤as

Para poder realizar el resumen de texto, necesitamos instalar las siguientes librer칤as:

```bash
pip install beautifulsoup4 lxml nltk
```

### 游볶 쯈u칠 es Beautiful Soup?

Beautiful Soup es una biblioteca de Python que facilita la extracci칩n de informaci칩n de archivos HTML y XML. Proporciona formas de navegar, buscar y modificar el 치rbol de an치lisis. Es 칰til para extraer informaci칩n de p치ginas web.

### 游 쯈u칠 es lxml?

lxml es una biblioteca de Python que permite el an치lisis y manipulaci칩n de documentos XML y HTML. Es muy r치pido y eficiente, y proporciona una API muy f치cil de usar.

_Para la libreria NLTK, no es necesario hablar ya que hemos estado trabajando con ella durante el transcurso de este curso._

## 游닇 Implementaci칩n

Para realizar el resumen de texto, primero necesitamos extraer el contenido de un art칤culo de una p치gina web. Tenemos que asegurarnos que el texto que queremos analizar tenga la etiqueta `<p>` para poder extraerlo correctamente. Ya que si no esta cargado de esta manera ser치 m치s complicado extraer el texto o no podremos extraerlo.

### 1. Extracci칩n de contenido web 游돚

El primer paso es descargar el contenido HTML de la p치gina web que deseamos analizar. Utilizaremos urllib para obtener el HTML de la p치gina y BeautifulSoup para procesarlo.

```python

import bs4 as bs
import urllib.request

# Descargar el contenido HTML de la p치gina
source = urllib.request.urlopen("{Nuestra pagina web con el texto que queremos sumarizar}").read()

# Analizar el HTML con BeautifulSoup
soup = bs.BeautifulSoup(source, "lxml")

# Extraer el idioma de la p치gina
html = soup.find("html")["lang"]
lang = "spanish" if "es" in html else "english"
```

En este c칩digo, se obtiene el HTML de la p치gina y se determina el idioma de la p치gina utilizando el atributo lang del elemento `<html>`

### 2. Limpieza del texto 游빛

El siguiente paso es extraer los p치rrafos del HTML y limpiar el texto eliminando referencias, espacios adicionales y caracteres no alfab칠ticos.

```python
# Extraer los p치rrafos del HTML
text = ""
for paragraph in soup.find_all("p"):
    text += paragraph.text + " "

# Limpiar el texto
import re

text = re.sub(r"\[[0-9]*\]", " ", text) # Eliminar referencias
text = re.sub(r"\s+", " ", text) # Eliminar espacios adicionales
text = re.sub(r"[^a-zA-Z]", " ", text) # Eliminar caracteres no alfab칠ticos
text = re.sub(r"\s+", " ", text) # Eliminar espacios adicionales
```

En este c칩digo, se extraen los p치rrafos del HTML y se limpia el texto utilizando expresiones regulares para eliminar referencias, espacios adicionales y caracteres no alfab칠ticos.

### 3. Tokenizaci칩n y eliminaci칩n de stopwords 游띔

Una vez que el texto est치 limpio, utilizamos NLTK para tokenizar las palabras y eliminar las palabras vac칤as (stopwords) que no aportan informaci칩n importante. Este proceso ya lo hemos visto en secciones anteriores.

    ```python
    from nltk.corpus import stopwords

    # Eliminar stopwords
    stop_words = set(stopwords.words(lang))
    words = nltk.word_tokenize(text)
    sentences = nltk.sent_tokenize(text)
    noStopWords = [word for word in words if word.lower() not in stop_words]
    ```

### 4. An치lisis de frecuencia de palabras 游늵

El siguiente paso es calcular la frecuencia de cada palabra en el texto. Calculamos la frecuencia de cada palabra en el texto utilizando nltk.FreqDist para determinar las palabras m치s comunes, que ser치n clave para puntuar las oraciones.

```python

frequencies = nltk.FreqDist(noStopWords)
frequencies.most_common(10) # Mostrar las 10 palabras m치s comunes
```

Ahora que tenemos las palabras m치s comunes, podemos obtener la frequencia maxima que la usaremos para calcular la puntuaci칩n de las oraciones. Ademas podemos seleccionar el n칰mero de oraciones que queremos en nuestro resumen.

```python
maxFrequency = frequencies.most_common(1)[0][1]
numberOfSentences = 5
```

### 5. Puntuaci칩n de las oraciones 游
